# 층: 딥러닝 구성 단위
# 예를 들어 
# 1. (samples, features) 크기의 2D 텐서가 저장된 간단한 벡터 데이터는 완전 연결 층fully connected layer이나 
# 밀집 층dense layer이라고도 불리는 밀집 연결 층densely connected layer에 의해 처리되는 경우가 많습니다(케라스에서는 Dense 클래스입니다).
# 2. (samples, timesteps, features) 크기의 3D 텐서로 저장된 시퀀스 데이터는 보통 LSTM 같은 순환 층recurrent layer에 의해 처리됩니다. 
# 3. 4D 텐서로 저장되어 있는 이미지 데이터는 일반적으로 2D 합성곱 층convolution layer에 의해 처리됩니다(Conv2D 클래스).

from keras import layers

# 3.1.1 층: 딥러닝 구성 단위
# 32개의 유닛으로 된 밀집 층
layer = layers.Dense(32, input_shape=(784,))  
# 첫 번째 차원이 784인 2D 텐서만 입력으로 받는 층을 만들었습니다
# (배치 차원인 0번째 축은 지정하지 않기 때문에 어떤 배치 크기도 입력으로 받을 수 있습니다) 
# 이 층은 첫 번째 차원 크기가 32로 변환된 텐서를 출력할 것입니다.
# 따라서 이 층에는 32차원의 벡터를 입력으로 받는 하위 층이 연결되어야 합니다.

from keras import models

model = models.Sequential()
model.add(layers.Dense(32, input_shape=(784,)))
model.add(layers.Dense(10))
# 두 번째 층에는 input_shape 매개변수를 지정하지 않았습니다. 
# 그 대신 앞선 층의 출력 크기를 입력 크기로 자동으로 채택합니다.


# 3.1.2 모델: 층의 네트워크
# 딥러닝 모델은 층으로 만든 비순환 유향 그래프Directed Acyclic Graph, DAG 3입니다.
# 가장 일반적 인 예가 하나의 입력을 하나의 출력으로 매핑하는 층을 순서대로 쌓는 것입니다.
# 네트워크 구조
#   1) 가지branch가 2개인 네트워크
#   2) 출력이 여러 개인 네트워크
#   3) 인셉션Inception 블록

# 네트워크 구조는 가설 공간hypothesis space을 정의합니다. 
# 1장에서 머신 러닝을 ‘가능성 있는 공간을 사전에 정의하고 피드백 신호의 도움을 받아 입력 데이터에 대한 유용한 변환을 찾는 것’으로 정의
# 네트워크 구조를 선택함으로써 가능성 있는 공간(가설 공간)을 
# 입력 데이터에서 출력 데이터로 매핑하는 일련의 특정 텐서 연산으로 제한하게 됩니다. 
# 우리가 찾아야 할 것은 이런 텐서 연산에 포함된 가중치 텐서의 좋은 값입니다.
# 딱 맞는 네트워크 구조를 찾아내는 것은 과학보다는 예술에 가깝습니다. 
# 신뢰할 만한 모범적인 사례와 원칙이 있지만 연습을 해야만 적절한 신경망을 설계할 수 있는 기술을 갖추게 될 것입니다. 
# 다음 몇 개의 장에서 신경망을 만드는 원리를 배우고 특정 문제에 적용 가능한 것과 그렇지 않은 것에 대한 직관을 길러 봅시다.


# 3.1.3 손실 함수와 옵티마이저: 학습 과정을 조절하는 열쇠
# 손실 함수loss function(목적 함수objective function): 훈련하는 동안 최소화될 값입니다. 주어진 문제에 대한 성공 지표가 됩니다.
# 옵티마이저optimizer: 손실 함수를 기반으로 네트워크가 어떻게 업데이트될지 결정합니다. 
# 특정 종류의 확률적 경사 하강법SGD을 구현합니다.

